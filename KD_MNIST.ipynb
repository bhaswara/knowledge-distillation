{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Distillation Tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, random_split \n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is to make sure we have the same output. In addition, it's also to make the code reproducible\n",
    "\n",
    "def set_seed(seed=None, seed_torch=True):\n",
    "    if seed is None:\n",
    "        seed = np.random.choice(2 ** 32)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if seed_torch:\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    print(f'Random seed {seed} has been set.')\n",
    "\n",
    "\n",
    "# In case that `DataLoader` is used\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random seed 123 has been set.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x20353d1c6d8>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SEED = 123\n",
    "set_seed(seed=SEED)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\envs\\env\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "#Import dataset. If you haven't download the data, then set the 'download=True'\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "trainset = datasets.MNIST(root='files_mnist/',\n",
    "                          download=False, train=True, transform=transform)\n",
    "train, valid = random_split(trainset,[50000,10000])\n",
    "\n",
    "testset = datasets.MNIST(root='files_mnist/',\n",
    "                          download=False, train=False, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = DataLoader(train, batch_size=32, shuffle=True, worker_init_fn=seed_worker, generator=g)\n",
    "valloader = DataLoader(valid, batch_size=32, shuffle=True, worker_init_fn=seed_worker, generator=g)\n",
    "testloader = DataLoader(testset, batch_size=32, shuffle=False, worker_init_fn=seed_worker, generator=g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n",
      "torch.Size([32])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2035d6ed4e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAANzklEQVR4nO3db6hc9Z3H8c9ntY0hrZiYSxI0mG7xiQobyxCUikbK+idP4h/Q+qD4L6aiQgs+2NBVqkIkrFvLPlAxXWOya1dRrtGg0q2rBSmKZJSsiUqrhsQaYu71H9GgcWO/++AeyzXe+c3NzJk/5vt+wTAz5ztnzpchn5yZ8zvn/hwRAnD4+7tBNwCgPwg7kARhB5Ig7EAShB1I4sh+bmzu3LmxaNGifm4SSGXHjh167733PFWtq7DbPk/Sv0k6QtK/R8Sa0usXLVqkZrPZzSYBFDQajZa1jr/G2z5C0l2Szpd0kqTLbJ/U6fsB6K1ufrMvkfRmRGyPiM8lPSRpeT1tAahbN2E/TtJfJj1/p1r2FbZX2m7abo6Pj3exOQDd6PnR+IhYGxGNiGiMjIz0enMAWugm7LskLZz0/PhqGYAh1E3YN0s60fb3bH9b0o8lbaqnLQB163joLSIO2L5B0n9rYuhtXUS8WltnAGrV1Th7RDwl6amaegHQQ5wuCyRB2IEkCDuQBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASfZ2yGZ3Ztm1bsX7nnXe2rK1fv77mbr7quuuuK9aXL289/d/ZZ59dXPfII/nnWSf27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQhCOibxtrNBrRbDb7tr1hMTY2Vqxfe+21xfpjjz1WrNs+1JZq0+7fT6m3e++9t7juihUrOuops0ajoWazOeWH3tVZC7Z3SPpY0heSDkREo5v3A9A7dZyidHZEvFfD+wDoIX6zA0l0G/aQ9HvbL9leOdULbK+03bTdHB8f73JzADrVbdjPiIgfSDpf0vW2zzz4BRGxNiIaEdEYGRnpcnMAOtVV2CNiV3U/JmmjpCV1NAWgfh2H3fYs29/98rGkcySVr8UEMDDdHI2fJ2ljNY56pKT/iojf1dLVN8y+ffuK9VWrVhXrjz/+eLHe7rruY489tmXtyiuvLK571FFHFevtrFmzpljfv39/y9rq1auL6zLOXq+Owx4R2yX9Q429AOghht6AJAg7kARhB5Ig7EAShB1Igr/VW4ONGzcW6xs2bCjWlywpn4t06623FuvnnHNOsd5L7YYFb7755pa1PXv2FNcdHR0t1i+++OJiHV/Fnh1IgrADSRB2IAnCDiRB2IEkCDuQBGEHkmCcvQYzZ84s1s8999xifd26dcX6/PnzD7mnfrnxxhuL9U2bNrWsbd68ubjuXXfdVawzzn5o2LMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKMs9eg3Xjv4TwePGPGjGK9NA5/6aWX1t0OCtizA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjLOjp0rTUVfTfaNP2u7Zba+zPWZ726Rlc2w/bfuN6n52b9sE0K3pfI1fL+m8g5atkvRMRJwo6ZnqOYAh1jbsEfGcpA8OWrxc0pdzGm2QdEG9bQGoW6cH6OZFxO7q8buS5rV6oe2Vtpu2m+Pj4x1uDkC3uj4aHxEhKQr1tRHRiIjGyMhIt5sD0KFOw77H9gJJqu7H6msJQC90GvZNki6vHl8uqfX4CoCh0Hac3faDkpZKmmv7HUm/lLRG0sO2r5a0U9IlvWwSw2tsrPyl7vnnn+/4va+66qqO18XXtQ17RFzWovSjmnsB0EOcLgskQdiBJAg7kARhB5Ig7EASXOKKrjzwwAPF+s6dO1vWjj766OK6S5cu7aQltMCeHUiCsANJEHYgCcIOJEHYgSQIO5AEYQeSYJwdRVu3bi3WV69e3fF7NxqNYv3444/v+L3xdezZgSQIO5AEYQeSIOxAEoQdSIKwA0kQdiAJxtmT27dvX7F+0UUXFesffHDwNIBfdcwxx7SsPfzww8V1US/27EAShB1IgrADSRB2IAnCDiRB2IEkCDuQBOPsh7lms1msX3PNNcX69u3bi/XSOLokPfLIIy1rs2fPLq6LerXds9teZ3vM9rZJy26xvcv2luq2rLdtAujWdL7Gr5d03hTLfx0Ri6vbU/W2BaBubcMeEc9JKp8TCWDodXOA7gbbr1Rf81v++LK90nbTdnN8fLyLzQHoRqdhv0fS9yUtlrRb0q9avTAi1kZEIyIaIyMjHW4OQLc6CntE7ImILyLir5J+I2lJvW0BqFtHYbe9YNLTCyVta/VaAMOh7Ti77QclLZU01/Y7kn4paantxZJC0g5JP+1di2inNJa+bFl5VPT9998v1ufMmVOsj46OFutnnnlmsY7+aRv2iLhsisX39aAXAD3E6bJAEoQdSIKwA0kQdiAJwg4kwSWu3wC33XZbsX733Xe3rLUbWmt3iWq7S2RPOOGEYh3Dgz07kARhB5Ig7EAShB1IgrADSRB2IAnCDiTBOPsQuOmmm4r122+/vVi33bJ21llnFde9//77i3XG0Q8f7NmBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnG2fvgxRdfLNbvueeeYj0iivVTTz21Ze3JJ58srjtz5sxiHYcP9uxAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kATj7DX46KOPivXly5d3tX7penWpPFb+xBNPFNftVrtzABYuXNiydvrpp9fdDgra7tltL7T9B9uv2X7V9s+q5XNsP237jep+du/bBdCp6XyNPyDpxog4SdJpkq63fZKkVZKeiYgTJT1TPQcwpNqGPSJ2R8TL1eOPJb0u6ThJyyVtqF62QdIFPeoRQA0O6QCd7UWSTpX0oqR5EbG7Kr0raV6LdVbabtpujo+Pd9MrgC5MO+y2vyNpVNLPI2Lv5FpMHKWZ8khNRKyNiEZENEZGRrpqFkDnphV229/SRNB/GxGPVov32F5Q1RdIGutNiwDq0HbozRPjPvdJej0i7pxU2iTpcklrqvvHe9LhN8CBAweK9b179xbr3XrhhRc6qtWh3dDbjBkzWtbmz59fXLfRaBTrp5xySrF+8sknt6x99tlnxXUvvPDCYn3WrFnF+jCazjj7DyX9RNJW21uqZb/QRMgftn21pJ2SLulJhwBq0TbsEfFHSa3O6vhRve0A6BVOlwWSIOxAEoQdSIKwA0kQdiAJLnGtwdy5c4v1Z599tli/4447ivUPP/zwkHuqS7PZLNY/+eSTYv3zzz9vWXv77beL67arP/roo8V66RyAdpcNtxuHX7FiRbE+jNizA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EASjLP3wWmnnVasj46O9qmTQ/fWW28V6/v37+/4vdevX1+sf/rpp8X6Qw89VKyXrndv9+e9r7jiimL9m4g9O5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4k4XZ/97tOjUYj2l0fDaBzjUZDzWZzyov12bMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBJtw257oe0/2H7N9qu2f1Ytv8X2Lttbqtuy3rcLoFPT+eMVByTdGBEv2/6upJdsP13Vfh0R/9q79gDUZTrzs++WtLt6/LHt1yUd1+vGANTrkH6z214k6VRJL1aLbrD9iu11tme3WGel7abt5vj4eHfdAujYtMNu+zuSRiX9PCL2SrpH0vclLdbEnv9XU60XEWsjohERjZGRke47BtCRaYXd9rc0EfTfRsSjkhQReyLii4j4q6TfSFrSuzYBdGs6R+Mt6T5Jr0fEnZOWL5j0sgslbau/PQB1mc7R+B9K+omkrba3VMt+Ieky24slhaQdkn7ag/4A1GQ6R+P/KGmq62Ofqr8dAL3CGXRAEoQdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5Ig7EAShB1IgrADSRB2IAnCDiRB2IEk+jpls+1xSTsnLZor6b2+NXBohrW3Ye1LordO1dnbCREx5d9/62vYv7ZxuxkRjYE1UDCsvQ1rXxK9dapfvfE1HkiCsANJDDrsawe8/ZJh7W1Y+5LorVN96W2gv9kB9M+g9+wA+oSwA0kMJOy2z7P9J9tv2l41iB5asb3D9tZqGurmgHtZZ3vM9rZJy+bYftr2G9X9lHPsDai3oZjGuzDN+EA/u0FPf9733+y2j5D0Z0n/KOkdSZslXRYRr/W1kRZs75DUiIiBn4Bh+0xJn0j6j4g4pVr2L5I+iIg11X+UsyPin4akt1skfTLoabyr2YoWTJ5mXNIFkq7QAD+7Ql+XqA+f2yD27EskvRkR2yPic0kPSVo+gD6GXkQ8J+mDgxYvl7SherxBE/9Y+q5Fb0MhInZHxMvV448lfTnN+EA/u0JffTGIsB8n6S+Tnr+j4ZrvPST93vZLtlcOupkpzIuI3dXjdyXNG2QzU2g7jXc/HTTN+NB8dp1Mf94tDtB93RkR8QNJ50u6vvq6OpRi4jfYMI2dTmsa736ZYprxvxnkZ9fp9OfdGkTYd0laOOn58dWyoRARu6r7MUkbNXxTUe/5cgbd6n5swP38zTBN4z3VNOMags9ukNOfDyLsmyWdaPt7tr8t6ceSNg2gj6+xPas6cCLbsySdo+GbinqTpMurx5dLenyAvXzFsEzj3WqacQ34sxv49OcR0febpGWaOCL/lqR/HkQPLfr6e0n/W91eHXRvkh7UxNe6/9PEsY2rJR0r6RlJb0j6H0lzhqi3/5S0VdIrmgjWggH1doYmvqK/ImlLdVs26M+u0FdfPjdOlwWS4AAdkARhB5Ig7EAShB1IgrADSRB2IAnCDiTx/zXJNSU5KCOUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Check the image \n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)\n",
    "\n",
    "plt.imshow(images[0].numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train teacher model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Teacher Model\n",
    "class teacher_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(teacher_net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "teacher_net(\n",
       "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc4): Linear(in_features=128, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teacher_model = teacher_net().to(device)\n",
    "teacher_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(teacher_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/10 \n",
      "Training Loss:1.6886 Training Acc:55.8 \n",
      "Validation Loss:0.6075 Validation Acc:82.4\n",
      "\n",
      "Epoch: 1/10 \n",
      "Training Loss:0.4556 Training Acc:86.8 \n",
      "Validation Loss:0.3718 Validation Acc:89.4\n",
      "\n",
      "Epoch: 2/10 \n",
      "Training Loss:0.3364 Training Acc:90.2 \n",
      "Validation Loss:0.3041 Validation Acc:91.4\n",
      "\n",
      "Epoch: 3/10 \n",
      "Training Loss:0.2786 Training Acc:91.9 \n",
      "Validation Loss:0.2560 Validation Acc:92.7\n",
      "\n",
      "Epoch: 4/10 \n",
      "Training Loss:0.2333 Training Acc:93.4 \n",
      "Validation Loss:0.2244 Validation Acc:93.6\n",
      "\n",
      "Epoch: 5/10 \n",
      "Training Loss:0.1973 Training Acc:94.4 \n",
      "Validation Loss:0.1890 Validation Acc:94.4\n",
      "\n",
      "Epoch: 6/10 \n",
      "Training Loss:0.1700 Training Acc:95.2 \n",
      "Validation Loss:0.1640 Validation Acc:95.1\n",
      "\n",
      "Epoch: 7/10 \n",
      "Training Loss:0.1485 Training Acc:95.8 \n",
      "Validation Loss:0.1461 Validation Acc:95.6\n",
      "\n",
      "Epoch: 8/10 \n",
      "Training Loss:0.1314 Training Acc:96.2 \n",
      "Validation Loss:0.1389 Validation Acc:95.9\n",
      "\n",
      "Epoch: 9/10 \n",
      "Training Loss:0.1174 Training Acc:96.6 \n",
      "Validation Loss:0.1267 Validation Acc:96.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    train_total = 0\n",
    "    \n",
    "    valid_loss = 0.0\n",
    "    valid_acc = 0.0\n",
    "    val_total = 0\n",
    "    \n",
    "    teacher_model.train()\n",
    "    for data, labels in trainloader:\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = teacher_model(data)\n",
    "        _, preds = torch.max(output, 1)\n",
    "        \n",
    "        loss = loss_fn(output, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_acc += torch.sum(preds == labels)\n",
    "        train_total += labels.size(0)\n",
    "        \n",
    "    teacher_model.eval()\n",
    "    for data, labels in valloader:\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        output = teacher_model(data)\n",
    "        _, preds = torch.max(output, 1)\n",
    "        \n",
    "        loss = loss_fn(output, labels)\n",
    "        \n",
    "        valid_loss += loss.item()\n",
    "        valid_acc += torch.sum(preds == labels)\n",
    "        val_total += labels.size(0)\n",
    "    \n",
    "    training_loss = train_loss / len(trainloader)\n",
    "    training_acc = (100 * train_acc) / (train_total)\n",
    "    validation_loss = valid_loss / len(valloader)\n",
    "    validation_acc = (100 * valid_acc) / (val_total)\n",
    "    \n",
    "    print(\"Epoch: {}/{} \\nTraining Loss:{:.4f} Training Acc:{:.1f} \\nValidation Loss:{:.4f} Validation Acc:{:.1f}\\n\".format(\n",
    "    epoch, epochs, training_loss, training_acc, validation_loss, validation_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 96.24 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for data, labels in testloader:\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = teacher_model(data)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item() \n",
    "    \n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train student model without distillation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Student Model\n",
    "class student_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(student_net, self).__init__()\n",
    "        self.fc1 = nn.Linear(784, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0],-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "student_net(\n",
       "  (fc1): Linear(in_features=784, out_features=50, bias=True)\n",
       "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "student_model = student_net().to(device)\n",
    "student_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(student_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/10 \n",
      "Training Loss:0.9995 Training Acc:76.7 \n",
      "Validation Loss:0.4671 Validation Acc:88.2\n",
      "\n",
      "Epoch: 1/10 \n",
      "Training Loss:0.4065 Training Acc:89.0 \n",
      "Validation Loss:0.3604 Validation Acc:89.9\n",
      "\n",
      "Epoch: 2/10 \n",
      "Training Loss:0.3449 Training Acc:90.3 \n",
      "Validation Loss:0.3247 Validation Acc:90.7\n",
      "\n",
      "Epoch: 3/10 \n",
      "Training Loss:0.3160 Training Acc:91.0 \n",
      "Validation Loss:0.3039 Validation Acc:91.3\n",
      "\n",
      "Epoch: 4/10 \n",
      "Training Loss:0.2955 Training Acc:91.7 \n",
      "Validation Loss:0.2870 Validation Acc:91.8\n",
      "\n",
      "Epoch: 5/10 \n",
      "Training Loss:0.2784 Training Acc:92.1 \n",
      "Validation Loss:0.2739 Validation Acc:92.0\n",
      "\n",
      "Epoch: 6/10 \n",
      "Training Loss:0.2637 Training Acc:92.6 \n",
      "Validation Loss:0.2600 Validation Acc:92.6\n",
      "\n",
      "Epoch: 7/10 \n",
      "Training Loss:0.2505 Training Acc:93.0 \n",
      "Validation Loss:0.2477 Validation Acc:92.9\n",
      "\n",
      "Epoch: 8/10 \n",
      "Training Loss:0.2385 Training Acc:93.3 \n",
      "Validation Loss:0.2400 Validation Acc:93.1\n",
      "\n",
      "Epoch: 9/10 \n",
      "Training Loss:0.2273 Training Acc:93.6 \n",
      "Validation Loss:0.2307 Validation Acc:93.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    train_total = 0\n",
    "    \n",
    "    valid_loss = 0.0\n",
    "    valid_acc = 0.0\n",
    "    val_total = 0\n",
    "    \n",
    "    student_model.train()\n",
    "    for data, labels in trainloader:\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = student_model(data)\n",
    "        _, preds = torch.max(output, 1)\n",
    "        \n",
    "        loss = loss_fn(output, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_acc += torch.sum(preds == labels)\n",
    "        train_total += labels.size(0)\n",
    "        \n",
    "    student_model.eval()\n",
    "    for data, labels in valloader:\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        output = student_model(data)\n",
    "        _, preds = torch.max(output, 1)\n",
    "        \n",
    "        loss = loss_fn(output, labels)\n",
    "        \n",
    "        valid_loss += loss.item()\n",
    "        valid_acc += torch.sum(preds == labels)\n",
    "        val_total += labels.size(0)\n",
    "    \n",
    "    training_loss = train_loss / len(trainloader)\n",
    "    training_acc = (100 * train_acc) / (train_total)\n",
    "    validation_loss = valid_loss / len(valloader)\n",
    "    validation_acc = (100 * valid_acc) / (val_total)\n",
    "    \n",
    "    print(\"Epoch: {}/{} \\nTraining Loss:{:.4f} Training Acc:{:.1f} \\nValidation Loss:{:.4f} Validation Acc:{:.1f}\\n\".format(\n",
    "    epoch, epochs, training_loss, training_acc, validation_loss, validation_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 93.66 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for data, labels in testloader:\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = student_model(data)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item() \n",
    "    \n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distillation Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(student_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_kd(scores, labels, targets, alpha=1, T=1):\n",
    "    p_s = F.log_softmax(scores/T, dim=1)\n",
    "    p_t = F.softmax(targets/T, dim=1)\n",
    "    distill_loss = nn.KLDivLoss()(p_s, p_t) * (T**2) \n",
    "    student_loss = F.cross_entropy(scores, labels)\n",
    "    \n",
    "    loss = alpha * student_loss + (1. - alpha) * distill_loss\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\Anaconda3\\envs\\env\\lib\\site-packages\\torch\\nn\\functional.py:2742: UserWarning: reduction: 'mean' divides the total loss by both the batch size and the support size.'batchmean' divides only by the batch size, and aligns with the KL div math definition.'mean' will be changed to behave the same as 'batchmean' in the next major release.\n",
      "  \"reduction: 'mean' divides the total loss by both the batch size and the support size.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/10 \n",
      "Training Loss:0.1250 Training Acc:93.9 \n",
      "Validation Loss:0.1273 Validation Acc:93.6\n",
      "\n",
      "Epoch: 1/10 \n",
      "Training Loss:0.1209 Training Acc:94.0 \n",
      "Validation Loss:0.1248 Validation Acc:93.9\n",
      "\n",
      "Epoch: 2/10 \n",
      "Training Loss:0.1174 Training Acc:94.1 \n",
      "Validation Loss:0.1211 Validation Acc:93.9\n",
      "\n",
      "Epoch: 3/10 \n",
      "Training Loss:0.1143 Training Acc:94.3 \n",
      "Validation Loss:0.1180 Validation Acc:94.0\n",
      "\n",
      "Epoch: 4/10 \n",
      "Training Loss:0.1112 Training Acc:94.4 \n",
      "Validation Loss:0.1167 Validation Acc:94.0\n",
      "\n",
      "Epoch: 5/10 \n",
      "Training Loss:0.1085 Training Acc:94.5 \n",
      "Validation Loss:0.1129 Validation Acc:94.1\n",
      "\n",
      "Epoch: 6/10 \n",
      "Training Loss:0.1060 Training Acc:94.6 \n",
      "Validation Loss:0.1109 Validation Acc:94.1\n",
      "\n",
      "Epoch: 7/10 \n",
      "Training Loss:0.1033 Training Acc:94.8 \n",
      "Validation Loss:0.1083 Validation Acc:94.2\n",
      "\n",
      "Epoch: 8/10 \n",
      "Training Loss:0.1010 Training Acc:94.9 \n",
      "Validation Loss:0.1067 Validation Acc:94.3\n",
      "\n",
      "Epoch: 9/10 \n",
      "Training Loss:0.0988 Training Acc:95.0 \n",
      "Validation Loss:0.1045 Validation Acc:94.4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "temperature = 2\n",
    "alpha=0.5\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "    train_total = 0\n",
    "    \n",
    "    valid_loss = 0.0\n",
    "    valid_acc = 0.0\n",
    "    val_total = 0\n",
    "    \n",
    "    student_model.train()\n",
    "    for data, labels in trainloader:\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        scores = student_model(data)\n",
    "        targets = teacher_model(data)\n",
    "        \n",
    "        _, preds = torch.max(scores, 1)\n",
    "        \n",
    "        loss = loss_kd(scores, labels, targets, alpha=alpha, T=temperature)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        train_acc += torch.sum(preds == labels)\n",
    "        train_total += labels.size(0)\n",
    "        \n",
    "    student_model.eval()\n",
    "    for data, labels in valloader:\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        scores = student_model(data)\n",
    "        targets = teacher_model(data)\n",
    "        \n",
    "        _, preds = torch.max(scores, 1)\n",
    "        \n",
    "        loss = loss_kd(scores, labels, targets, alpha=alpha, T=temperature)\n",
    "        \n",
    "        valid_loss += loss.item()\n",
    "        valid_acc += torch.sum(preds == labels)\n",
    "        val_total += labels.size(0)\n",
    "    \n",
    "    training_loss = train_loss / len(trainloader)\n",
    "    training_acc = (100 * train_acc) / (train_total)\n",
    "    validation_loss = valid_loss / len(valloader)\n",
    "    validation_acc = (100 * valid_acc) / (val_total)\n",
    "    \n",
    "    print(\"Epoch: {}/{} \\nTraining Loss:{:.4f} Training Acc:{:.1f} \\nValidation Loss:{:.4f} Validation Acc:{:.1f}\\n\".format(\n",
    "    epoch, epochs, training_loss, training_acc, validation_loss, validation_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 94.63 %\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for data, labels in testloader:\n",
    "        data = data.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = student_model(data)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item() \n",
    "    \n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
